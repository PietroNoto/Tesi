{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower case document content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decapitalize_content(pages: list[str]):\n",
    "\n",
    "    \"\"\"Turns document content into lower case\"\"\"\n",
    "\n",
    "    for p in pages:\n",
    "        p.page_content = p.page_content.lower()\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removes non ASCII characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_non_ASCII(pages: list[str]):\n",
    "\n",
    "    \"\"\"Removes non ASCII characters from document. Not suitable for many non english languages \n",
    "    which have several non ASCII characters \"\"\"\n",
    "\n",
    "    for p in pages:\n",
    "        p.page_content = re.sub(r'[^\\x00-\\x7F]+', '', p.page_content)\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removes bulleted and numbered lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_bullets(pages: list[str]):\n",
    "\n",
    "    \"\"\"Removes bullets from document \"\"\"\n",
    "\n",
    "    for p in pages:\n",
    "        p.page_content = re.sub(r'^[→•\\-*✔●✗]\\s*', '', p.page_content, flags = re.MULTILINE)\n",
    "        p.page_content = re.sub(r'\\d+\\.\\s*', '', p.page_content)\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removes multiple consecutive escape characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_escape(pages: list[str]):\n",
    "\n",
    "    \"\"\"Turns multiple consecutive escape characters into a single white space\"\"\"\n",
    "    \n",
    "    for p in pages:\n",
    "        p.page_content = ' '.join(p.page_content.split())\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all file paths from source folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder = \"../sources\"\n",
    "files = []\n",
    "\n",
    "for f in os.listdir(folder):\n",
    "    file = os.path.join(folder, f)\n",
    "    if os.path.isfile(file):\n",
    "        files.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse documents into pages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(\"../sources/VDA.pdf\")\n",
    "pages = []\n",
    "\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process content (text cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_pages = remove_non_ASCII(pages)\n",
    "cleaned_pages = decapitalize_content(cleaned_pages)\n",
    "cleaned_pages = remove_bullets(cleaned_pages)\n",
    "cleaned_pages = remove_escape(cleaned_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 jin et al. multi-source domain adaptation (msda). when running our method for msda, we similarly merge multiple source domains in mcc and compare it to existing da algorithms that are specically designed for msda on domainnet. as shown in table 1, based on the inductive bias of minimizing the class confusion, mcc signicantly outperforms m3sda [31], the state-of-the-art method by a big margin (0%). note that these specic methods are of very complex architecture and loss designs and may be hard to use in practical applications. table 1: accuracy (%) on domainnet for mtda and msda (resnet-101). (a) mtda method c: i: p: q: r: s: avg resnet [13] 6 8 8 2 6 3 1 se [7] 3 5 5 8 0 7 6 mcd [36] 1 1 0 4 2 5 7 dada [32] 1 0 5 9 7 8 5 mcc 6 0 4 5 0 3 8 (b) msda method :c :i :p :q :r :s avg resnet [13] 6 0 1 3 9 7 9 mcd [36] 3 1 7 6 4 5 5 dctn [48] 6 5 8 2 5 3 2 m3sda [31] 6 0 3 3 7 5 6 mcc 5 0 6 5 0 7 6 partial domain adaptation (pda). due to the existence of source outlier classes, pda is known as a challenging scenario because of the misalignment between the source and target classes. for a fair comparison, we follow the protocol of pada [3] and afn [49], where the rst 25 categories (in alphabetic order) of the oce-home dataset are taken as the target domain. as shown in table 2, on this dataset, mcc outperforms afn [49], the iccv19 honorable-mention entry and the state-of-the-art method for pda, by a big margin (3%). table 2: accuracy (%) on oce-home for pda (resnet-50). method (s:t) a:c a:p a:r c:a c:p c:r p:a p:c p:r r:a r:c r:p avg resnet [13] 6 8 2 9 1 9 7 9 8 4 8 4 7 dan [21] 4 8 5 8 2 1 9 1 4 4 5 3 3 jan [24] 9 2 9 4 7 0 8 4 3 9 4 8 3 pada [3] 2 0 7 2 8 0 6 2 8 7 6 1 0 afn [49] 9 3 4 4 0 8 4 3 4 8 4 9 8 mcc 1 8 0 8 1 1 0 8 9 6 2 8 1 unsupervised domain adaptation (uda). we evaluate mcc for the most common uda scenario on several datasets. (1) visda-as reported in table 3, mcc surpasses state-of-the-art uda algorithms and yields the highest accuracy to date among methods of no complex architecture and loss designs. (2) oce-as shown in table 4, mcc performs the best. (3) two moon [20]. we train a shallow mlp from scratch and plot the decision boundaries of mcc and minimum entropy (minent) [10]. mcc yields much better boundaries in fig.\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_pages[9].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse content with Unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Reading PDF for file: ../sources/VDA.pdf ...\n"
     ]
    }
   ],
   "source": [
    "from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "loader = UnstructuredLoader(file_path = \"../sources/VDA.pdf\", strategy = \"hi_res\")\n",
    "docs = []\n",
    "async for doc in loader.alazy_load():\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print(doc.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
