{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split documents into pages, with text only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "import os\n",
    "\n",
    "\n",
    "folder = \"../sources\"\n",
    "files = []\n",
    "\n",
    "for fname in os.listdir(folder):\n",
    "    complete_path = os.path.join(folder, fname)\n",
    "    if os.path.isfile(complete_path):\n",
    "        files.append(complete_path)\n",
    "\n",
    "docs = []\n",
    "for file in files:\n",
    "    loader = PyMuPDFLoader(file)\n",
    "    async for doc in loader.alazy_load():\n",
    "        docs.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove first pages and index pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [doc for doc in docs if doc.metadata[\"page\"] != 0]\n",
    "\n",
    "docs = [doc for doc in docs \n",
    "        if not doc.page_content.lower().startswith((\"index\", \"table of contents\", \"índice\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate text with image descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"../indexing/image_descriptions/image_descriptions.json\", \"r\") as f:\n",
    "    image_descriptions = json.load(f)\n",
    "\n",
    "    for imd in image_descriptions:\n",
    "        file = f\"../sources/{imd[\"file\"]}.pdf\"\n",
    "        page = imd[\"page\"]\n",
    "        doc = next(filter(lambda doc: doc.metadata[\"source\"] == file and doc.metadata[\"page\"] == page, docs), None)\n",
    "        if doc != None:\n",
    "            doc.page_content += f\"\\n{imd[\"image_description\"]}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def decapitalize_content(pages: list[str]):\n",
    "\n",
    "    \"\"\"Turns document content into lower case\"\"\"\n",
    "\n",
    "    for p in pages:\n",
    "        p.page_content = p.page_content.lower()\n",
    "\n",
    "\n",
    "def remove_non_ASCII(pages: list[str]):\n",
    "\n",
    "    \"\"\"Removes non ASCII characters from document. Not suitable for many non english languages \n",
    "    which have several non ASCII characters \"\"\"\n",
    "\n",
    "    for p in pages:\n",
    "        if \"non-en\" not in p.metadata[\"keywords\"]:\n",
    "            p.page_content = re.sub(r\"[^\\x00-\\x7F]+\", \"\", p.page_content)\n",
    "\n",
    "\n",
    "def remove_bullets(pages: list[str]):\n",
    "\n",
    "    \"\"\"Removes bullets from document \"\"\"\n",
    "\n",
    "    for p in pages:\n",
    "        p.page_content = re.sub(r\"^[→•▪\\-*✔➢●✗]\\s*\", \"\", p.page_content, flags = re.MULTILINE)\n",
    "        p.page_content = re.sub(r\"\\d+\\.(?=\\s*[a-zA-Z])\", \"\", p.page_content)\n",
    "\n",
    "\n",
    "def remove_escape(pages: list[str]):\n",
    "\n",
    "    \"\"\"Turns multiple consecutive escape characters into a single white space\"\"\"\n",
    "    \n",
    "    for p in pages:\n",
    "        p.page_content = ' '.join(p.page_content.split())\n",
    "\n",
    "\n",
    "remove_non_ASCII(docs)\n",
    "decapitalize_content(docs)\n",
    "remove_bullets(docs)\n",
    "remove_escape(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "import os\n",
    "\n",
    "\n",
    "def merge_and_split(docs: list[Document], splitter):\n",
    "\n",
    "    from collections import defaultdict\n",
    "    \n",
    "\n",
    "    docs_groups = defaultdict(list)\n",
    "    for doc in docs:\n",
    "        docs_groups[doc.metadata[\"source\"]].append(doc)\n",
    "\n",
    "    giant_docs = []\n",
    "    for _, docs in docs_groups.items():\n",
    "        giant_doc = {}\n",
    "        metadata = {k: v for k, v in docs[0].metadata.items() if k != \"page\"}\n",
    "        page_content = \"\"\n",
    "        for doc in docs:\n",
    "            page_content += doc.page_content\n",
    "        giant_doc[\"metadata\"] = metadata\n",
    "        giant_doc[\"page_content\"] = page_content\n",
    "        giant_docs.append(giant_doc)\n",
    "\n",
    "    files = []\n",
    "    for gdoc in giant_docs:\n",
    "        page_contents = splitter.split_text(gdoc[\"page_content\"])\n",
    "        files += [{\"metadata\": gdoc[\"metadata\"], \"page_content\": pc} for pc in page_contents]\n",
    "\n",
    "    files = [Document(metadata = file[\"metadata\"], page_content = file[\"page_content\"]) for file in files]\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def save_chunks(pages: list, path: str):\n",
    "\n",
    "    from langchain_core.load import dumpd\n",
    "    import json\n",
    "    import os\n",
    "\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    for chunk in range(len(pages)):\n",
    "        full_path = path + \"/\" + \"chunk_\" + str(chunk + 1)\n",
    "        with open(full_path, \"w\") as ser_file:\n",
    "            page_d = dumpd(pages[chunk])\n",
    "            json.dump(page_d, ser_file)\n",
    "\n",
    "\n",
    "chunk_size = 2_000\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap = chunk_size/10,\n",
    "    add_start_index = True,\n",
    ")\n",
    "\n",
    "docs = merge_and_split(docs, text_splitter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup agent for QA generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint = \"https://keystone1.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview\",\n",
    "    api_key = os.environ[\"OPENAI_API_KEY\"],\n",
    "    api_version = \"2024-08-01-preview\",\n",
    "    azure_deployment = \"gpt-4o\",\n",
    "    max_tokens = 256\n",
    ")\n",
    "\n",
    "path = \"../indexing/models/Text+Images/multilingual/256_20/256_20_multilingual\"\n",
    "vector_store = InMemoryVectorStore.load(path = path, \n",
    "                                        embedding = HuggingFaceEmbeddings(model_name = \"intfloat/multilingual-e5-large\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_generation_prompt_1 = \"\"\"\n",
    "Your task is to write a question and an answer given a context, country, year and, optionally, a target, which can be clinic (dental practise) and/or lab (laboratory).\n",
    "Your question should be and answerable with a one-sentenced factual answer from the context.\n",
    "This means that your question MUST NOT mention something like \"according to the passage/map/picture/graph/chart/line\" or \"context\".\n",
    "Identify, if any, a country from the context and refer to it when you formulate the question, otherwise use the country provided.\n",
    "Alongside the country, enrich the question with the year provided, for example: \"Which is the top brand in France in 2023?\"\n",
    "Additionally, if the target is either clinic or lab (but not both) you should mention it in your question.\n",
    "All words of both the answer and the question must be in english.\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Output:::\n",
    "Question: (your question)\n",
    "Answer: (your answer to the question)\n",
    "\n",
    "Here is the context, country, year and target.\n",
    "\n",
    "Context: {context}\\n\n",
    "Country: {country}\\n\n",
    "Year: {year}\\n\n",
    "Target: {target}\\n\n",
    "Output:::\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_generation_prompt_2 = \"\"\"\n",
    "Your task is to write a question and an answer given a context, two vars and a constant.\n",
    "Your question should be and answerable with a one-sentenced factual answer from the context.\n",
    "This means that your question MUST NOT mention something like \"according to the passage/map/picture/graph/chart/line/context\".\n",
    "In your question you should ask to make a comparison between data in the context between var_1 and var_2 provided. \n",
    "You should enrich your question with the costants and the vars provided.\n",
    "All words of both the answer and the question must be in english.\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Output:::\n",
    "Question: (your question)\n",
    "Answer: (your answer to the question)\n",
    "\n",
    "Here is the context, var1, var2 and constant.\n",
    "\n",
    "Context: {context}\\n\n",
    "Var1: {var1}\\n\n",
    "Var2: {var2}\\n\n",
    "Constant1: {constant1}\\n\n",
    "Constant2: {constant2}\\n\n",
    "Output:::\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate QA couples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "N_GENERATIONS = 15\n",
    "outputs = []\n",
    "\n",
    "for doc in tqdm(random.sample(docs, N_GENERATIONS)):\n",
    "    context = doc.page_content\n",
    "    keywords = json.loads(\"{\" + doc.metadata[\"keywords\"] + \"}\")\n",
    "    country = keywords[\"country\"]\n",
    "    year = keywords[\"year\"]\n",
    "    target = keywords[\"target\"] if \"target\" in keywords else None\n",
    "\n",
    "    output_QA = llm.invoke(QA_generation_prompt_1.format(context = context, \n",
    "                                                       country = country, \n",
    "                                                       year = year, \n",
    "                                                       target = target)).content\n",
    "    question = output_QA.split(\"Question: \")[-1].split(\"Answer: \")[0]\n",
    "    answer = output_QA.split(\"Answer: \")[-1]\n",
    "    outputs.append(\n",
    "        {\n",
    "            \"context\": context,\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"source_doc\": doc.metadata[\"source\"],\n",
    "        }\n",
    "    )\n",
    "    sleep(5)\n",
    "\n",
    "with open(\"../evaluation/dataset/all_QA_with_images_2.json\", \"w\") as f:\n",
    "    json.dump(outputs, f, indent = 4, ensure_ascii = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2015, 2017, 2019, 2021, 2022, 2023, 2024]\n",
    "countries = [\"France\", \"Spain\", \"Germany\", \"UK\", \"Italy\", \"Brazil\"]\n",
    "brands = [\"3shape\", \"Dentsply Sirona\", \"Sirona\", \"Ivoclair\", \"Bego\", \"3M\", \"Ines Icore\", \"Caresstream\" \"Amann Girbach\"]\n",
    "products = [\"Intraoral scanner\", \"3d printer\"]\n",
    "\n",
    "# to be chosen randomly\n",
    "constant_1 = 2021\n",
    "constant_2 = \"Italy\"\n",
    "var_1 = \"3shape\"\n",
    "var_2 = \"Dentsply Sirona\"\n",
    "\n",
    "docs_1 = vector_store.similarity_search(f\"{var_1}\", k = 4, filter = lambda doc: f\"{year}\" in doc.metadata[\"keywords\"])\n",
    "docs_2 = vector_store.similarity_search(f\"{var_2}\", k = 4, filter = lambda doc: f\"{year}\" in doc.metadata[\"keywords\"])\n",
    "context = \" \".join([doc.page_content for doc in docs_1 + docs_2])\n",
    "\n",
    "output_QA = llm.invoke(QA_generation_prompt_2.format(context = context, var1 = var_1, var2 = var_2, constant = constant_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='558fce50-390f-42e2-a9c2-b699bf37eb7a', metadata={'source': '../sources/OMNI_DIGITAL_EU_21_CLI_LAB_INTEGRATED_.pdf', 'file_path': '../sources/OMNI_DIGITAL_EU_21_CLI_LAB_INTEGRATED_.pdf', 'total_pages': 49, 'format': 'PDF 1.7', 'title': 'Presentazione standard di PowerPoint', 'author': 'Arianna', 'subject': '', 'keywords': '\"country\": \"Europe\",\"year\": 2021,\"target\": \"all\"', 'creator': 'Microsoft® PowerPoint® per Microsoft 365', 'producer': 'Microsoft® PowerPoint® per Microsoft 365', 'creationDate': \"D:20220323172425+01'00'\", 'modDate': \"D:20220323172425+01'00'\", 'trapped': ''}, page_content=\" are as follows: 1. **3shape** - 55% 2. **itero** - 41% 3. **dentsply sirona** - 39% 4. **medit** - 26% 5. **caresstream** - 24% 6. **planmeca** - 9% 7. **3m** - 4% 8. **dental wings** - 4% 9. **straumann** - 3% 10. **condor** - 3% 11. **kulzer** - 2% 12. **other** - 6% 13. **don't know / no answer** - 2% beneath the bars and corresponding percentages, there's a footnote that indicates the base is 524 cases. there is a list of bullet points above and on the side that provides extended data and observations about the preferred brands. the chart itself is a blue bar graph with different lengths of bars corresponding to the listed brand names indicating their usage or preference within the survey. the visual layout suggests a data-driven investigation, aiming to present the most popular intra-oral scanning device brands based on a sample survey. the brands 3shape, itero, and dentsply sirona clearly dominate the survey responses.intraoral scanners\"),\n",
       " Document(id='7ca1c918-b214-41a0-9838-5d4af921b4b1', metadata={'source': '../sources/OMNI_DIGITAL_EU_21_CLI_LAB_INTEGRATED_.pdf', 'file_path': '../sources/OMNI_DIGITAL_EU_21_CLI_LAB_INTEGRATED_.pdf', 'total_pages': 49, 'format': 'PDF 1.7', 'title': 'Presentazione standard di PowerPoint', 'author': 'Arianna', 'subject': '', 'keywords': '\"country\": \"Europe\",\"year\": 2021,\"target\": \"all\"', 'creator': 'Microsoft® PowerPoint® per Microsoft 365', 'producer': 'Microsoft® PowerPoint® per Microsoft 365', 'creationDate': \"D:20220323172425+01'00'\", 'modDate': \"D:20220323172425+01'00'\", 'trapped': ''}, page_content=' the clinician, do you recommend a specific intra-oral scanner brand? which intra-oral scanner brand do you recommend most often? 3shape is quoted more than average among big sized labs (49%), by the lab owners (39%), less recently open structures and those stating the business has decreased (40% and 46% respectively). itero is quoted more than average among more recently open labs (25%) and among labs receiving a high share of scan files (22%). less than average among labs performing a high share of prosthetic complex cases (12%). medit is quoted more than average among labs receiving a lower share of scan files (23%). dentsply sirona is quoted more than average among labs receiving scan files from more than half of clients (20%). labo recommendation is very high: on an overall basis, at least 90% of the laboratories approached by dentists recommend a brand. 3shape is the most recommended brand in spain and italy, while itero is most recommended in the uk. carestream has adopted a very widespread distribution and commercial strategy, which explains the high number of recommendations in italy (achieving a significantly higher penetration than in the other analysed countries). diverse recommended brands across the surveyed countries: 3shape is most'),\n",
       " Document(id='90eb9a55-8e6f-43ba-aec5-25bdfa13a26e', metadata={'source': '../sources/OMNI_DIGITAL_EU_21_CLI_LAB_INTEGRATED_.pdf', 'file_path': '../sources/OMNI_DIGITAL_EU_21_CLI_LAB_INTEGRATED_.pdf', 'total_pages': 49, 'format': 'PDF 1.7', 'title': 'Presentazione standard di PowerPoint', 'author': 'Arianna', 'subject': '', 'keywords': '\"country\": \"Europe\",\"year\": 2021,\"target\": \"all\"', 'creator': 'Microsoft® PowerPoint® per Microsoft 365', 'producer': 'Microsoft® PowerPoint® per Microsoft 365', 'creationDate': \"D:20220323172425+01'00'\", 'modDate': \"D:20220323172425+01'00'\", 'trapped': ''}, page_content=\" itero, and dentsply sirona clearly dominate the survey responses.intraoral scanners brands: recommendation vs scan files reception when asked by the clinician, which intra-oral scanner brand do you recommend most often? what are the top 3 brands of the intra-oral scanners that you receive files from? 25 full digital workflow labo at overall level, a possible relationship between the brand of the ios from which the scan is received and the recommendation of the ios brand has been investigated. the results show that 3shape has the highest relationship between the brand from which the labs receive the scanner and the recommendation. it is also true that 3shape, due to its popularity and seniority in the ios market, has a high frequency of recommendation even in labs receiving scans from other brands. in fact, it is always cited as the second brand regardless of the brand of ios from which the labs receive scans (for carestream it is the first). this also shows that 3shape's reputation is very high. base: 524 cases 3shape dentsply sirona itero medit carestream planmeca 3shape 55% 26% 29% 24% 33% 17% dentsply sirona 12% 30% 9% 5\"),\n",
       " Document(id='0cdbaff0-779c-41c7-88cd-b6ab3359aa2a', metadata={'source': '../sources/OMNI_DIGITAL_EU_21_CLI_LAB_INTEGRATED_.pdf', 'file_path': '../sources/OMNI_DIGITAL_EU_21_CLI_LAB_INTEGRATED_.pdf', 'total_pages': 49, 'format': 'PDF 1.7', 'title': 'Presentazione standard di PowerPoint', 'author': 'Arianna', 'subject': '', 'keywords': '\"country\": \"Europe\",\"year\": 2021,\"target\": \"all\"', 'creator': 'Microsoft® PowerPoint® per Microsoft 365', 'producer': 'Microsoft® PowerPoint® per Microsoft 365', 'creationDate': \"D:20220323172425+01'00'\", 'modDate': \"D:20220323172425+01'00'\", 'trapped': ''}, page_content=' the right, there is a large bar chart that lists \"full digital workflow\" labeled at the top with \"3shape\" at the top of the chart with \"55%,\" \"itero\" beneath with \"41%,\" followed by \"dentsply sirona\" with \"39%,\" \"medit\" with \"26%,\" \"carestream\" with \"24%,\" and \"planmeca\" with just \"9%.\" the left side of the pie chart reiterates \"88%\" in its blue portion and \"12%\" in the brown portion, which correlates with the pie chart that is part of the full page. below the main pie chart, additional notes explain various user survey behaviors and responses to brand preferences for intra-oral scanners. the image contains a bar chart that describes the top intraoral scanners brands when receiving scan files. the chart\\'s title states \"what are the top 3 brands of the intra-oral scanners that you receive files from?\" below which is the logo and a brief introductory question. on the right side of the image is a series of horizontal bars each representing a brand and its percentage value. the brands and their respective percentages are as follows: 1. **3shape** - 55% 2. **itero** -')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: In 2021, which brand between 3shape and Dentsply Sirona had a higher recommendation percentage according to the survey data?\\n\\nAnswer: In 2021, 3shape had a higher recommendation percentage than Dentsply Sirona.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_QA.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
